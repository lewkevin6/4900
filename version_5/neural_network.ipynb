{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow.python'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lewke\\Desktop\\4900\\version_5\\neural_network.ipynb Cell 1\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lewke/Desktop/4900/version_5/neural_network.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompose\u001b[39;00m \u001b[39mimport\u001b[39;00m ColumnTransformer\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lewke/Desktop/4900/version_5/neural_network.ipynb#W0sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpreprocessing\u001b[39;00m \u001b[39mimport\u001b[39;00m OneHotEncoder, StandardScaler\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lewke/Desktop/4900/version_5/neural_network.ipynb#W0sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/lewke/Desktop/4900/version_5/neural_network.ipynb#W0sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mhealthcare-dataset-stroke-data.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/lewke/Desktop/4900/version_5/neural_network.ipynb#W0sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m balanced_data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mdropna()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tensorflow\\__init__.py:39\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m KerasLazyLoader \u001b[39mas\u001b[39;00m _KerasLazyLoader\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.python'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import tensorflow as tf\n",
    "\n",
    "data = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "balanced_data = data.dropna()\n",
    "balanced_data = balanced_data.drop(columns= \"id\")\n",
    "balanced_data = balanced_data[balanced_data.age > 20]\n",
    "balanced_data = balanced_data.drop(balanced_data.index[balanced_data[\"gender\"] == \"Other\"])\n",
    "balanced_data = balanced_data.drop(balanced_data.index[balanced_data[\"work_type\"] == \"Never_worked\"])\n",
    "\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', \"bmi\", \"smoking_status\"]\n",
    "cat_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'hypertension', 'heart_disease']\n",
    "num_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "bal_data_train, bal_data_test = train_test_split(balanced_data, train_size = 0.8, random_state=1, stratify= balanced_data[\"stroke\"])\n",
    "bal_data_train, bal_data_val = train_test_split(bal_data_train, train_size = 0.8, random_state=1)\n",
    "\n",
    "X_train = bal_data_train.drop('stroke', axis = 1)\n",
    "y_train = bal_data_train['stroke']\n",
    "\n",
    "X_val = bal_data_val.drop('stroke', axis = 1)\n",
    "y_val = bal_data_val['stroke']\n",
    "\n",
    "X_test = bal_data_test.drop('stroke', axis = 1)\n",
    "y_test = bal_data_test['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer([\n",
    "    ('one-hot-encoder', OneHotEncoder(sparse_output=False), cat_columns),\n",
    "    ('scaler', StandardScaler(), num_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = preprocessing.fit_transform(X_train)\n",
    "X_val2 = preprocessing.transform(X_val)\n",
    "X_test2 = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=10))\n",
    "model.add(tf.keras.layers.Dense(200, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(100, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(50, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, \"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "#model.summary()\n",
    "model_history = model.fit(X_train2, y_train, validation_data=(X_val2, y_val), epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://imbalanced-learn.org/stable/miscellaneous.html\n",
    "\n",
    "https://www.freecodecamp.org/news/binary-classification-made-simple-with-tensorflow/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
