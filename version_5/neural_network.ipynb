{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "data = pd.read_csv(\"healthcare-dataset-stroke-data.csv\")\n",
    "\n",
    "balanced_data = data.dropna()\n",
    "balanced_data = balanced_data.drop(columns= \"id\")\n",
    "balanced_data = balanced_data[balanced_data.age > 20]\n",
    "balanced_data = balanced_data.drop(balanced_data.index[balanced_data[\"gender\"] == \"Other\"])\n",
    "balanced_data = balanced_data.drop(balanced_data.index[balanced_data[\"work_type\"] == \"Never_worked\"])\n",
    "\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', \"bmi\", \"smoking_status\"]\n",
    "cat_columns = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'hypertension', 'heart_disease']\n",
    "num_columns = ['age', 'avg_glucose_level', 'bmi']\n",
    "\n",
    "bal_data_train, bal_data_test = train_test_split(balanced_data, train_size = 0.8, random_state=1, stratify= balanced_data[\"stroke\"])\n",
    "bal_data_train, bal_data_val = train_test_split(bal_data_train, train_size = 0.8, random_state=1)\n",
    "\n",
    "X_train = bal_data_train.drop('stroke', axis = 1)\n",
    "y_train = bal_data_train['stroke']\n",
    "\n",
    "X_val = bal_data_val.drop('stroke', axis = 1)\n",
    "y_val = bal_data_val['stroke']\n",
    "\n",
    "X_test = bal_data_test.drop('stroke', axis = 1)\n",
    "y_test = bal_data_test['stroke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = ColumnTransformer([\n",
    "    ('one-hot-encoder', OneHotEncoder(sparse_output=False), cat_columns),\n",
    "    ('scaler', StandardScaler(), num_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = preprocessing.fit_transform(X_train)\n",
    "X_val2 = preprocessing.transform(X_val)\n",
    "X_test2 = preprocessing.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial model starts at 0.07 recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               10752     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 273,921\n",
      "Trainable params: 273,921\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(1)\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=20))\n",
    "model.add(tf.keras.layers.Dense(512, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(512, 'relu'))\n",
    "model.add(tf.keras.layers.Dense(1, \"sigmoid\"))\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=['Recall'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 1s 7ms/step - loss: 0.1976 - recall: 0.0078 - val_loss: 0.2033 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1696 - recall: 0.0000e+00 - val_loss: 0.1989 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1656 - recall: 0.0000e+00 - val_loss: 0.1991 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1591 - recall: 0.0000e+00 - val_loss: 0.2015 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 0s 5ms/step - loss: 0.1568 - recall: 0.0000e+00 - val_loss: 0.2074 - val_recall: 0.0263\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1507 - recall: 0.0234 - val_loss: 0.2152 - val_recall: 0.0000e+00\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1473 - recall: 0.0469 - val_loss: 0.2280 - val_recall: 0.0789\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1452 - recall: 0.0625 - val_loss: 0.2233 - val_recall: 0.0789\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1407 - recall: 0.0703 - val_loss: 0.2330 - val_recall: 0.0263\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 0s 4ms/step - loss: 0.1351 - recall: 0.0703 - val_loss: 0.2330 - val_recall: 0.0789\n"
     ]
    }
   ],
   "source": [
    "model_history = model.fit(X_train2, y_train, validation_data=(X_val2, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2334 - recall: 0.0238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.2334386706352234, 0.02380952425301075]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test2, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://imbalanced-learn.org/stable/miscellaneous.html\n",
    "\n",
    "https://www.freecodecamp.org/news/binary-classification-made-simple-with-tensorflow/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
