{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import in clean data from data_visualization.pynb to this notebook and split it into train and validate set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "#Read in newly cleaned data from data_visualization.pynb\n",
    "\n",
    "cleaned_data = pd.read_csv(\"cleaned_data.csv\")\n",
    "\n",
    "features = ['gender', 'age', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'avg_glucose_level', \"bmi\", \"smoking_status\"]\n",
    "X = cleaned_data[features]\n",
    "y = cleaned_data.stroke\n",
    "\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metric of Success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#Test bench to test success for every model I create\n",
    "def test(prediction):\n",
    "    print(\"Recall score:\", metrics.recall_score(val_y, prediction))\n",
    "    print(\"Precision score:\", metrics.precision_score(val_y, prediction))\n",
    "    print(\"F1 score:\", metrics.f1_score(val_y, prediction))\n",
    "    print(\"AUC:\", metrics.roc_auc_score(val_y, prediction))\n",
    "    print(\"Confusion Matrix:\\n\", metrics.confusion_matrix(val_y, prediction))\n",
    "\n",
    "\n",
    "#Consider some things like AUC curve\n",
    "#https://towardsdatascience.com/metrics-to-evaluate-your-machine-learning-algorithm-f10ba6e38234\n",
    "\n",
    "#Precision recall tradeoff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the model for other files to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def transfer_model(model):\n",
    "    return joblib.dump(model, 'model_for_app_1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score: 0.06896551724137931\n",
      "Precision score: 0.06451612903225806\n",
      "F1 score: 0.06666666666666667\n",
      "AUC: 0.5096752308191498\n",
      "Confusion Matrix:\n",
      " [[1111   58]\n",
      " [  54    4]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_for_app_1.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "decision_tree_model = DecisionTreeClassifier(random_state = 1)\n",
    "\n",
    "decision_tree_model.fit(train_X,train_y)\n",
    "\n",
    "decision_tree_model_prediction = decision_tree_model.predict(val_X)\n",
    "\n",
    "test(decision_tree_model_prediction)\n",
    "\n",
    "transfer_model(decision_tree_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
